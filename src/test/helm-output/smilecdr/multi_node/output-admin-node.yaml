---
# Source: smilecdr/templates/scdr/scdr-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-scdrnode-admin
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: admin
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: smilecdr
      smilecdr/nodeName: admin
---
# Source: smilecdr/templates/scdr/scdr-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-scdrnode-fhir
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: fhir
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: smilecdr
      smilecdr/nodeName: fhir
---
# Source: smilecdr/templates/scdr/scdr-file-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-scdr-smileutil
  namespace: default
  labels:
    helm.sh/chart: No Chart Version - Unit Testing
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: No App Version - Unit Testing
    app.kubernetes.io/managed-by: Helm
data:
  smileutil: |-
    #!/bin/bash

    # ----------------------------------------------------------------------------
    # CDR CLI Tool for use in Helm Chart deployment
    #

    # CDR home directory is hard coded as this is not configurable with the Helm Chart deployment method.
    CDRDIR=/home/smile/smilecdr/

    # Change the working directory to the CDR home directory
    cd $CDRDIR

    # Build the classpath
    CLASSPATH="$CDRDIR/classes:$CDRDIR/lib/*:$CDRDIR/customerlib/*"

    # Unset JAVA_TOOL_OPTIONS as it will cause failure if it includes any listeners (i.e. for JMX agent)
    unset JAVA_TOOL_OPTIONS

    JAVA_CMD="java $JAVA_OPTS -cp $CLASSPATH -Dsmile.basedir=$CDRDIR -Djava.io.tmpdir=$CDRDIR/tmp ca.cdr.cli.App $*"
    $JAVA_CMD
---
# Source: smilecdr/templates/scdr/scdr-file-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-scdr-smileutil
  namespace: default
  labels:
    helm.sh/chart: No Chart Version - Unit Testing
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: No App Version - Unit Testing
    app.kubernetes.io/managed-by: Helm
data:
  smileutil: |-
    #!/bin/bash

    # ----------------------------------------------------------------------------
    # CDR CLI Tool for use in Helm Chart deployment
    #

    # CDR home directory is hard coded as this is not configurable with the Helm Chart deployment method.
    CDRDIR=/home/smile/smilecdr/

    # Change the working directory to the CDR home directory
    cd $CDRDIR

    # Build the classpath
    CLASSPATH="$CDRDIR/classes:$CDRDIR/lib/*:$CDRDIR/customerlib/*"

    # Unset JAVA_TOOL_OPTIONS as it will cause failure if it includes any listeners (i.e. for JMX agent)
    unset JAVA_TOOL_OPTIONS

    JAVA_CMD="java $JAVA_OPTS -cp $CLASSPATH -Dsmile.basedir=$CDRDIR -Djava.io.tmpdir=$CDRDIR/tmp ca.cdr.cli.App $*"
    $JAVA_CMD
---
# Source: smilecdr/templates/scdr/scdr-node-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-scdrnode-adminnode
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: admin
data:
  cdr-config-Master.properties: |-
    ################################################################################
    # Node Configuration
    ################################################################################
    node.id 	= AdminNode
    node.propertysource 	= PROPERTIES
    node.config.locked 	= true
    node.security.strict 	= false

    module.clustermgr.config.messagebroker.type                         =EMBEDDED_ACTIVEMQ

    ################################################################################
    # Other Modules are Configured Below
    ################################################################################

    # The following setting controls where module configuration is ultimately stored.
    # When set to "DATABASE" (which is the default), the clustermgr configuration is
    # always read but the other modules are stored in the database upon the first
    # launch and their configuration is read from the database on subsequent
    # launches. When set to "PROPERTIES", values in this file are always used.
    #
    # In other words, in DATABASE mode, the module definitions below this line are
    # only used to seed the database upon the very first startup of the sytem, and
    # will be ignored after that. In PROPERTIES mode, the module definitions below
    # are read every time the system starts, and existing definitions and config are
    # overwritten by what is in this file.
    #
    ################################################################################
    # ENDPOINT: JSON Admin Services
    ################################################################################
    module.admin_json.type 	= ADMIN_JSON
    module.admin_json.requires.SECURITY_IN_UP 	= local_security
    module.admin_json.config.context_path 	= /json-admin
    module.admin_json.config.port 	= 9000
    ################################################################################
    # ENDPOINT: Web Admin
    ################################################################################
    module.admin_web.type 	= ADMIN_WEB
    module.admin_web.requires.SECURITY_IN_UP 	= local_security
    module.admin_web.config.context_path 	= /
    module.admin_web.config.port 	= 9100
    ################################################################################
    # External Audit DB Config
    ################################################################################
    module.audit.type 	= AUDIT_LOG_PERSISTENCE
    module.audit.config.db.driver 	= POSTGRES_9_4
    module.audit.config.db.password 	= #{env['DB_PASS']}
    module.audit.config.db.schema_update_mode 	= UPDATE
    module.audit.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.audit.config.db.username 	= #{env['DB_USER']}
    ################################################################################
    # Cluster Manager Configuration
    ################################################################################
    module.clustermgr.config.db.driver 	= POSTGRES_9_4
    module.clustermgr.config.db.password 	= #{env['DB_PASS']}
    module.clustermgr.config.db.schema_update_mode 	= UPDATE
    module.clustermgr.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.clustermgr.config.db.username 	= #{env['DB_USER']}
    ################################################################################
    # Local Storage Inbound Security
    ################################################################################
    module.local_security.type 	= SECURITY_IN_LOCAL
    ################################################################################
    # External Transaction Log DB
    ################################################################################
    module.transaction.type 	= TRANSACTION_LOG_PERSISTENCE
    module.transaction.config.db.driver 	= POSTGRES_9_4
    module.transaction.config.db.password 	= #{env['DB_PASS']}
    module.transaction.config.db.schema_update_mode 	= UPDATE
    module.transaction.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.transaction.config.db.username 	= #{env['DB_USER']}
---
# Source: smilecdr/templates/scdr/scdr-node-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-scdrnode-fhirnode
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: fhir
data:
  cdr-config-Master.properties: |-
    ################################################################################
    # Node Configuration
    ################################################################################
    node.id 	= FhirNode
    node.propertysource 	= PROPERTIES
    node.config.locked 	= true
    node.security.strict 	= false

    module.clustermgr.config.messagebroker.type                         =EMBEDDED_ACTIVEMQ

    ################################################################################
    # Other Modules are Configured Below
    ################################################################################

    # The following setting controls where module configuration is ultimately stored.
    # When set to "DATABASE" (which is the default), the clustermgr configuration is
    # always read but the other modules are stored in the database upon the first
    # launch and their configuration is read from the database on subsequent
    # launches. When set to "PROPERTIES", values in this file are always used.
    #
    # In other words, in DATABASE mode, the module definitions below this line are
    # only used to seed the database upon the very first startup of the sytem, and
    # will be ignored after that. In PROPERTIES mode, the module definitions below
    # are read every time the system starts, and existing definitions and config are
    # overwritten by what is in this file.
    #
    ################################################################################
    # External Audit DB Config
    ################################################################################
    module.audit.type 	= AUDIT_LOG_PERSISTENCE
    module.audit.config.db.driver 	= POSTGRES_9_4
    module.audit.config.db.password 	= #{env['DB_PASS']}
    module.audit.config.db.schema_update_mode 	= NONE
    module.audit.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.audit.config.db.username 	= #{env['DB_USER']}
    ################################################################################
    # Cluster Manager Configuration
    ################################################################################
    module.clustermgr.config.db.driver 	= POSTGRES_9_4
    module.clustermgr.config.db.password 	= #{env['DB_PASS']}
    module.clustermgr.config.db.schema_update_mode 	= NONE
    module.clustermgr.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.clustermgr.config.db.username 	= #{env['DB_USER']}
    ################################################################################
    # ENDPOINT: FHIR Service
    ################################################################################
    module.fhir_endpoint.type 	= ENDPOINT_FHIR_REST
    module.fhir_endpoint.requires.PERSISTENCE_ALL 	= persistence
    module.fhir_endpoint.requires.SECURITY_IN_UP 	= local_security
    module.fhir_endpoint.config.base_url.fixed 	= https://smilecdr-example.local/fhir_request
    module.fhir_endpoint.config.context_path 	= /fhir_request
    module.fhir_endpoint.config.port 	= 8000
    ################################################################################
    # Local Storage Inbound Security
    ################################################################################
    module.local_security.type 	= SECURITY_IN_LOCAL
    ################################################################################
    # Database Configuration
    ################################################################################
    module.persistence.type 	= PERSISTENCE_R4
    module.persistence.config.db.driver 	= POSTGRES_9_4
    module.persistence.config.db.password 	= #{env['DB_PASS']}
    module.persistence.config.db.schema_update_mode 	= NONE
    module.persistence.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.persistence.config.db.username 	= #{env['DB_USER']}
    ################################################################################
    # External Transaction Log DB
    ################################################################################
    module.transaction.type 	= TRANSACTION_LOG_PERSISTENCE
    module.transaction.config.db.driver 	= POSTGRES_9_4
    module.transaction.config.db.password 	= #{env['DB_PASS']}
    module.transaction.config.db.schema_update_mode 	= NONE
    module.transaction.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
    module.transaction.config.db.username 	= #{env['DB_USER']}
---
# Source: smilecdr/templates/scdr/scdr-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-scdrnode-adminnode-admin-json
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: admin
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: admin-json
      port: 9000
      targetPort: 9000
      protocol: TCP
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: smilecdr
    smilecdr/nodeName: admin
---
# Source: smilecdr/templates/scdr/scdr-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-scdrnode-adminnode-admin-web
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: admin
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: admin-web
      port: 9100
      targetPort: 9100
      protocol: TCP
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: smilecdr
    smilecdr/nodeName: admin
---
# Source: smilecdr/templates/scdr/scdr-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-scdrnode-fhirnode-fhir
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: fhir
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: fhir
      port: 8000
      targetPort: 8000
      protocol: TCP
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: smilecdr
    smilecdr/nodeName: fhir
---
# Source: smilecdr/templates/scdr/scdr-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-scdrnode-admin
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: admin
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: smilecdr
      smilecdr/nodeName: admin
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: smilecdr
        app.kubernetes.io/version: No App Version - Unit Testing
        helm.sh/chart: No Chart Version - Unit Testing
        smilecdr/nodeName: admin
    spec:
      imagePullSecrets:
        []
      serviceAccountName: default
      securityContext:
        fsGroup: 1000
      initContainers:
        []
      terminationGracePeriodSeconds: 60
      containers:
        - name: smilecdr
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "docker.smilecdr.com/smilecdr:2024.05.R05"
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["sleep", "30"]
          startupProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - /bin/grep "Smile, we're up and running! :)" /home/smile/smilecdr/log/smile.log
            failureThreshold: 30
            periodSeconds: 10
          readinessProbe:
            failureThreshold: 2
            httpGet:
              path: /endpoint-health
              port: 9100
            periodSeconds: 10
            timeoutSeconds: 10
          resources:
            limits:
              memory: 4Gi
            requests:
              cpu: "1"
          env:
            - name: GLOBALENVVARNAME
              value: my-global-env-var-value
            - name: JVMARGS
              value: -server -Xms2048m -Xmx2048m -Djava.io.tmpdir=/home/smile/smilecdr/tmp -Dsun.net.inetaddr.ttl=60
                -Djava.security.egd=file:/dev/./urandom
            - name: MYADMINENVVAR
              value: my-admin-node-env-var-value
          ports:
            - containerPort: 9000
              name: admin-json
              protocol: TCP
            - containerPort: 9100
              name: admin-web
              protocol: TCP
          volumeMounts:
            - mountPath: /home/smile/smilecdr/classes/cdr-config-Master.properties
              name: scdr-config-release-name
              subPath: cdr-config-Master.properties
            - mountPath: /home/smile/smilecdr/bin/smileutil
              name: scdr-smileutil
              subPath: smileutil
            - mountPath: /home/smile/smilecdr/tmp
              name: scdr-volume-tmp
            - mountPath: /home/smile/smilecdr/log
              name: scdr-volume-log
            - mountPath: /home/smile/smilecdr/activemq-data
              name: scdr-volume-amq
      volumes:
        - configMap:
            name: release-name-scdrnode-adminnode
          name: scdr-config-release-name
        - configMap:
            defaultMode: 504
            name: release-name-scdr-smileutil
          name: scdr-smileutil
        - emptyDir:
            sizeLimit: 1Mi
          name: scdr-volume-tmp
        - emptyDir:
            sizeLimit: 5Gi
          name: scdr-volume-log
        - emptyDir:
            sizeLimit: 10Mi
          name: scdr-volume-amq
      restartPolicy: Always
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/instance: release-name
            app.kubernetes.io/name: smilecdr
            smilecdr/nodeName: admin
        matchLabelKeys:
        - pod-template-hash
        maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: ScheduleAnyway
      - labelSelector:
          matchLabels:
            app.kubernetes.io/instance: release-name
            app.kubernetes.io/name: smilecdr
            smilecdr/nodeName: admin
        matchLabelKeys:
        - pod-template-hash
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: smilecdr/templates/scdr/scdr-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-scdrnode-fhir
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: fhir
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: smilecdr
      smilecdr/nodeName: fhir
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: smilecdr
        app.kubernetes.io/version: No App Version - Unit Testing
        helm.sh/chart: No Chart Version - Unit Testing
        smilecdr/nodeName: fhir
    spec:
      imagePullSecrets:
        []
      serviceAccountName: default
      securityContext:
        fsGroup: 1000
      initContainers:
        []
      terminationGracePeriodSeconds: 60
      containers:
        - name: smilecdr
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "docker.smilecdr.com/smilecdr:2024.05.R05"
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["sleep", "30"]
          startupProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - /bin/grep "Smile, we're up and running! :)" /home/smile/smilecdr/log/smile.log
            failureThreshold: 30
            periodSeconds: 10
          readinessProbe:
            failureThreshold: 2
            httpGet:
              path: /fhir_request/endpoint-health
              port: 8000
            periodSeconds: 10
            timeoutSeconds: 10
          resources:
            limits:
              memory: 4Gi
            requests:
              cpu: "1"
          env:
            - name: GLOBALENVVARNAME
              value: my-fhir-node-overridden-value
            - name: JVMARGS
              value: -server -Xms2048m -Xmx2048m -Djava.io.tmpdir=/home/smile/smilecdr/tmp -Dsun.net.inetaddr.ttl=60
                -Djava.security.egd=file:/dev/./urandom
            - name: MYFHIRENVVAR
              value: my-fhir-node-env-var-value
          ports:
            - containerPort: 8000
              name: fhir
              protocol: TCP
          volumeMounts:
            - mountPath: /home/smile/smilecdr/classes/cdr-config-Master.properties
              name: scdr-config-release-name
              subPath: cdr-config-Master.properties
            - mountPath: /home/smile/smilecdr/bin/smileutil
              name: scdr-smileutil
              subPath: smileutil
            - mountPath: /home/smile/smilecdr/tmp
              name: scdr-volume-tmp
            - mountPath: /home/smile/smilecdr/log
              name: scdr-volume-log
            - mountPath: /home/smile/smilecdr/activemq-data
              name: scdr-volume-amq
      volumes:
        - configMap:
            name: release-name-scdrnode-fhirnode
          name: scdr-config-release-name
        - configMap:
            defaultMode: 504
            name: release-name-scdr-smileutil
          name: scdr-smileutil
        - emptyDir:
            sizeLimit: 1Mi
          name: scdr-volume-tmp
        - emptyDir:
            sizeLimit: 10Gi
          name: scdr-volume-log
        - emptyDir:
            sizeLimit: 10Mi
          name: scdr-volume-amq
      restartPolicy: Always
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/instance: release-name
            app.kubernetes.io/name: smilecdr
            smilecdr/nodeName: fhir
        matchLabelKeys:
        - pod-template-hash
        maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: ScheduleAnyway
      - labelSelector:
          matchLabels:
            app.kubernetes.io/instance: release-name
            app.kubernetes.io/name: smilecdr
            smilecdr/nodeName: fhir
        matchLabelKeys:
        - pod-template-hash
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: smilecdr/templates/scdr/scdr-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-scdr
  namespace: default
  labels:
    helm.sh/chart: No Chart Version - Unit Testing
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: No App Version - Unit Testing
    app.kubernetes.io/managed-by: Helm
  annotations:
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  ingressClassName: nginx
  rules:
    - host: smilecdr-example.local
      http:
        paths:
        - backend:
            service:
              name: release-name-scdrnode-adminnode-admin-json
              port:
                number: 9000
          path: /json-admin
          pathType: Prefix
        - backend:
            service:
              name: release-name-scdrnode-adminnode-admin-web
              port:
                number: 9100
          path: /
          pathType: Prefix
        - backend:
            service:
              name: release-name-scdrnode-fhirnode-fhir
              port:
                number: 8000
          path: /fhir_request
          pathType: Prefix
---
# Source: smilecdr/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-adminnode-test-connection"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: admin
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['release-name-scdrnode-adminnode-admin-web:9100']
      resources:
        limits:
          cpu: 10m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 128Mi
  restartPolicy: Never
---
# Source: smilecdr/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-fhirnode-test-connection"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
    smilecdr/nodeName: fhir
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['release-name-scdrnode-fhirnode-fhir:8000']
      resources:
        limits:
          cpu: 10m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 128Mi
  restartPolicy: Never

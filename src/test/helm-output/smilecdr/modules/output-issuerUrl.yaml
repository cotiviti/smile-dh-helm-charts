---
# Source: smilecdr/templates/scdr/scdr-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-scdr
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: smilecdr
---
# Source: smilecdr/templates/scdr/scdr-node-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-scdr-masterdev-node
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
data:
  cdr-config-Master.properties: |-
    ################################################################################
    # Node Configuration
    ################################################################################
    node.id 	= Masterdev
    node.propertysource 	= PROPERTIES
    node.config.locked 	= true
    node.security.strict 	= false

    module.clustermgr.config.messagebroker.type                         =EMBEDDED_ACTIVEMQ

    ################################################################################
    # Other Modules are Configured Below
    ################################################################################

    # The following setting controls where module configuration is ultimately stored.
    # When set to "DATABASE" (which is the default), the clustermgr configuration is
    # always read but the other modules are stored in the database upon the first
    # launch and their configuration is read from the database on subsequent
    # launches. When set to "PROPERTIES", values in this file are always used.
    #
    # In other words, in DATABASE mode, the module definitions below this line are
    # only used to seed the database upon the very first startup of the sytem, and
    # will be ignored after that. In PROPERTIES mode, the module definitions below
    # are read every time the system starts, and existing definitions and config are
    # overwritten by what is in this file.
    #
    ################################################################################
    # ENDPOINT: Web Admin
    ################################################################################
    module.admin_web.type 	= ADMIN_WEB
    module.admin_web.requires.SECURITY_IN_UP 	= local_security
    module.admin_web.config.context_path 	= /
    module.admin_web.config.https_forwarding_assumed 	= true
    module.admin_web.config.port 	= 9100
    module.admin_web.config.respect_forward_headers 	= true
    module.admin_web.config.tls.enabled 	= false
    ################################################################################
    # Modified Cluster Manager Configuration
    ################################################################################
    module.clustermgr.config.audit_log.request_headers_to_store 	= Content-Type,Host
    module.clustermgr.config.db.driver 	= POSTGRES_9_5
    module.clustermgr.config.db.schema_update_mode 	= UPDATE
    module.clustermgr.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:5432/#{env['DB_DATABASE']}?sslmode=require
    module.clustermgr.config.stats.heartbeat_persist_frequency_ms 	= 15000
    module.clustermgr.config.stats.stats_cleanup_frequency_ms 	= 300000
    module.clustermgr.config.stats.stats_persist_frequency_ms 	= 60000
    ################################################################################
    # ENDPOINT: FHIR Service
    ################################################################################
    module.fhir_endpoint.type 	= ENDPOINT_FHIR_REST_R4
    module.fhir_endpoint.requires.PERSISTENCE_R4 	= persistence
    module.fhir_endpoint.requires.SECURITY_IN_UP 	= local_security
    module.fhir_endpoint.config.base_url.fixed 	= https://smilecdr-example.local/fhir_request
    module.fhir_endpoint.config.context_path 	= /fhir_request
    module.fhir_endpoint.config.port 	= 8000
    ################################################################################
    # Local Storage Inbound Security
    ################################################################################
    module.local_security.type 	= SECURITY_IN_LOCAL
    module.local_security.config.password_encoding_type 	= BCRYPT_12_ROUND
    module.local_security.config.seed.users.file 	= classpath:/config_seeding/users.json
    ################################################################################
    # Database Configuration
    ################################################################################
    module.persistence.type 	= PERSISTENCE_R4
    module.persistence.config.db.driver 	= POSTGRES_9_4
    module.persistence.config.db.password 	= #{env['DB_PASS']}
    module.persistence.config.db.url 	= jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']/#{env['DB_DATABASE']}?sslmode=require
    module.persistence.config.db.username 	= #{env['DB_USER']}
    ################################################################################
    # security_out_smart
    ################################################################################
    module.security_out_smart.type 	= SECURITY_OUT_SMART
    module.security_out_smart.requires.SECURITY_IN_UP 	= local_security
    module.security_out_smart.config.cors.enable 	= true
    module.security_out_smart.config.enforce_approved_scopes_to_restrict_permissions 	= false
    module.security_out_smart.config.federate_mode.enabled 	= true
    module.security_out_smart.config.issuer.url 	= https://my-issuer-url/path
    module.security_out_smart.config.openid.signing.keystore_id 	= default-keystore
    module.security_out_smart.config.port 	= 9300


  smileutil: |-
    #!/bin/bash

    # ----------------------------------------------------------------------------
    # CDR CLI Tool for use in Helm Chart deployment
    #

    # CDR home directory is hard coded as this is not configurable with the Helm Chart deployment method.
    CDRDIR=/home/smile/smilecdr/

    # Change the working directory to the CDR home directory
    cd $CDRDIR

    # Build the classpath
    CLASSPATH="$CDRDIR/classes:$CDRDIR/lib/*:$CDRDIR/customerlib/*"

    # Unset JAVA_TOOL_OPTIONS as it will cause failure if it includes any listeners (i.e. for JMX agent)
    unset JAVA_TOOL_OPTIONS

    JAVA_CMD="java $JAVA_OPTS -cp $CLASSPATH -Dsmile.basedir=$CDRDIR -Djava.io.tmpdir=$CDRDIR/tmp ca.cdr.cli.App $*"
    $JAVA_CMD
---
# Source: smilecdr/templates/scdr/scdr-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-scdr-svc-admin-web
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: admin-web
      port: 9100
      targetPort: 9100
      protocol: TCP
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: smilecdr
---
# Source: smilecdr/templates/scdr/scdr-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-scdr-svc-fhir
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: fhir
      port: 8000
      targetPort: 8000
      protocol: TCP
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: smilecdr
---
# Source: smilecdr/templates/scdr/scdr-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-scdr
  namespace: default
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: smilecdr
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: smilecdr
        app.kubernetes.io/version: No App Version - Unit Testing
        helm.sh/chart: No Chart Version - Unit Testing
    spec:
      imagePullSecrets:
        []
      serviceAccountName: default
      securityContext:
        fsGroup: 1000
      initContainers:
        []
      terminationGracePeriodSeconds: 60
      containers:
        - name: smilecdr
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "docker.smilecdr.com/smilecdr:2024.11.PRE-13"
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["sleep", "30"]
          startupProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - /bin/grep "Smile, we're up and running! :)" /home/smile/smilecdr/log/smile.log
            failureThreshold: 30
            periodSeconds: 10
          readinessProbe:
            failureThreshold: 2
            httpGet:
              path: /fhir_request/endpoint-health
              port: 8000
            periodSeconds: 10
            timeoutSeconds: 10
          resources:
            limits:
              memory: 4Gi
            requests:
              cpu: "1"
          env:
            - name: JVMARGS
              value: -server -Xms2048m -Xmx2048m -Djava.io.tmpdir=/home/smile/smilecdr/tmp -Dsun.net.inetaddr.ttl=60
                -Djava.security.egd=file:/dev/./urandom
          ports:
            - containerPort: 9100
              name: admin-web
              protocol: TCP
            - containerPort: 8000
              name: fhir
              protocol: TCP
          volumeMounts:
            - mountPath: /home/smile/smilecdr/classes/cdr-config-Master.properties
              name: scdr-config-release-name
              subPath: cdr-config-Master.properties
            - mountPath: /home/smile/smilecdr/bin/smileutil
              name: scdr-smileutil
              subPath: smileutil
            - mountPath: /home/smile/smilecdr/tmp
              name: scdr-volume-tmp
            - mountPath: /home/smile/smilecdr/log
              name: scdr-volume-log
            - mountPath: /home/smile/smilecdr/activemq-data
              name: scdr-volume-amq
      volumes:
        - configMap:
            name: release-name-scdr-masterdev-node
          name: scdr-config-release-name
        - configMap:
            defaultMode: 504
            name: release-name-scdr-masterdev-node
          name: scdr-smileutil
        - emptyDir:
            sizeLimit: 1Mi
          name: scdr-volume-tmp
        - emptyDir:
            sizeLimit: 10Gi
          name: scdr-volume-log
        - emptyDir:
            sizeLimit: 10Mi
          name: scdr-volume-amq
      restartPolicy: Always
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/instance: release-name
            app.kubernetes.io/name: smilecdr
        matchLabelKeys:
        - pod-template-hash
        maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: ScheduleAnyway
      - labelSelector:
          matchLabels:
            app.kubernetes.io/instance: release-name
            app.kubernetes.io/name: smilecdr
        matchLabelKeys:
        - pod-template-hash
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: smilecdr/templates/scdr/scdr-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-scdr
  namespace: default
  labels:
    helm.sh/chart: No Chart Version - Unit Testing
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: No App Version - Unit Testing
    app.kubernetes.io/managed-by: Helm
  annotations:
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  ingressClassName: nginx
  rules:
    - host: smilecdr-example.local
      http:
        paths:
        - backend:
            service:
              name: release-name-scdr-svc-admin-web
              port:
                number: 9100
          path: /
          pathType: Prefix
        - backend:
            service:
              name: release-name-scdr-svc-fhir
              port:
                number: 8000
          path: /fhir_request
          pathType: Prefix
---
# Source: smilecdr/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-smilecdr-test-connection"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: smilecdr
    app.kubernetes.io/version: No App Version - Unit Testing
    helm.sh/chart: No Chart Version - Unit Testing
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['smilecdr-admin_web:9100']
      resources:
        limits:
          cpu: 10m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 128Mi
  restartPolicy: Never

# Module Configuration
Configuring modules is fairly straight forward, but somewhat different
than the existing methods using the `cdr-config-Master.properties` file.
This file is still used behind the scenes, but it is generated by the Helm Chart
and included in the application deployment.

> **NOTE**: When using Helm Charts, they become the 'single source of truth' for
your configuration. This means that repeatable, consistent deployments become a
breeze. It also means you should not edit your configuration options in the Smile CDR web
admin console.

You can define your modules in your main values file, or you can define them
in separate files and include them using the `-f` command. This is possible because Helm
[accepts multiple values files](https://helm.sh/docs/chart_template_guide/values_files/)

We recommend defining them in one or more separate files, as this allows you
to manage common settings as well as per-environment overlays. We will discuss this further
down in the Advanced Configuration section below.

## Mapping traditional Smile CDR configuration to Helm

Mapping existing configurations to values files is relatively straight forwards:
### Identify the module configuration parameter.
e.g. [Concurrent Bundle Validation](https://smilecdr.com/docs/configuration_categories/fhir_performance.html#property-concurrent-bundle-validation)
Config.properties format:
`module.persistence.config.dao_config.concurrent_bundle_validation = false`
### Specify them in th values yaml file format:
```yaml
modules:
  persistence:
    config:
      dao_config.concurrent_bundle_validation: "false"
```
The same effective mapping can be used for any module configurations supported by Smile CDR.
## Module definition considerations
Here are some additional fields/considerations that need to be included in your module definitions files:

* Though not strictly required by the `yaml` spec, all values should be quoted.
  You may run into trouble with some values if you do not quote them.
  Specifically, values starting with `*` or `#` will fail if not quoted.
* The `module id` is taken from the yaml key name.
* Modules can be defined, but disabled. They need to be enabled with the `enabled: true` entry.
* Modules other than the cluster manager need to define `type`. A list of module types is available [here](https://smilecdr.com/docs/product_reference/enumerated_types.html#module-types)
* Modules which expose an endpoint need to de defined with a `service` entry, which includes `enabled` and `svcName` entries.
* DB credentials/details can be referenced from your module configurations via `DB_XXX` environment variables.

Any configurations you specify will merge with the defaults, priority going to the values file.

### Disabling included default module definitios
If you wish to disable any of the default modules, we recommend you disable all default modules and define
your own from scratch. This way it will be easier to determine the exact modules you have defined just by
looking at your values files.
You can disable all default modules using:
```yaml
modules:
  useDefaultModules: false
```
You use the `default-modules.yaml` file as a reference by untarring the Helm Chart.

Here is an example of what your module definition may look like when configuring
Smile CDR with the `clustermgr`, `persistence`, `local_security`,
`fhir_endpoint` and `admin_web` modules.
#### `my-module-values.yaml`
<details>
  <summary>Click to expand</summary>

```yaml
modules:
  useDefaultModules: false
  clustermgr:
    name: Cluster Manager Configuration
    enabled: true
    config:
      db.driver: POSTGRES_9_4
      db.url: jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
      db.password: "#{env['DB_PASS']}"
      db.username: "#{env['DB_USER']}"
  persistence:
    name: Database Configuration
    enabled: true
    type: PERSISTENCE_R4
    config:
      db.driver: POSTGRES_9_4
      db.url: jdbc:postgresql://#{env['DB_URL']}:#{env['DB_PORT']}/#{env['DB_DATABASE']}?sslmode=require
      db.password: "#{env['DB_PASS']}"
      db.username: "#{env['DB_USER']}"
  local_security:
    name: Local Storage Inbound Security
    enabled: true
    type: SECURITY_IN_LOCAL
    config:
      seed.users.file: classpath:/config_seeding/users.json
      password_encoding_type: BCRYPT_12_ROUND
  admin_web:
    name: Web Admin
    enabled: true
    type: ADMIN_WEB
    service:
      enabled: true
      svcName: admin-web
      hostName: default
    requires:
      SECURITY_IN_UP: local_security
    config:
      context_path: ""
      port: 9100
      tls.enabled: false
      https_forwarding_assumed: true
      respect_forward_headers: true
  fhir_endpoint:
    name: FHIR Service
    enabled: true
    type: ENDPOINT_FHIR_REST_R4
    service:
      enabled: true
      svcName: fhir
      hostName: default
    requires:
      PERSISTENCE_R4: persistence
      SECURITY_IN_UP: local_security
    config:
      context_path: fhir_request
      port: 8000
      base_url.fixed: default
```
</details>

### Define Readiness Probe
As Kubernetes only supports a single readiness probe per container, you need to define which endpoint module Kubernetes should use to consider the 'readiness' of your installation.

The default modules included with this chart are configured so that the `fhir_endpoint` module is used for the readiness probe. This is done by setting the `enableReadinessProbe` key to `true` in the module definition.

If you wish to use a different module for the readiness probe, you must disable it for the `fhir_endpoint` module and enable it for the module of your choice. e.g.

#### `my-module-values.yaml`

```yaml
modules:
  fhir_endpoint:
    enableReadinessProbe: false
  my_fhir_endpoint:
    enableReadinessProbe: true
    enabled: true
    ...
```
Alternatively, you may disable the included default modules as described above, and then enable the probe on one of your custom defined modules.

>**Note:** You must enable the readiness probe for exactly one endpoint module. If you specify none, or more than one, the Helm Chart will return an error.
## Install Smile CDR with extra modules definition files

When splitting your configuration into multiple `values` files, pass them in to your `helm upgrade` commandline like so:
```shell
$ helm upgrade -i my-smile-env --devel -f my-values.yaml -f my-module-values.yaml smiledh/smilecdr
```
